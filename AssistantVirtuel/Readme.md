
# Assistant Vocal Intelligent
====================================
Assistant vocal capable de :
- ğŸ™ï¸ Enregistrer ou recevoir un fichier audio
- ğŸ“ Transcrire la parole en texte
- ğŸ¤– GÃ©nÃ©rer une rÃ©ponse avec GPT-3.5 ou DeepSeek localement
- ğŸ”Š Lire la rÃ©ponse avec synthÃ¨se vocale
- ğŸ–¥ï¸ Fournir une interface web simple avec historique et export

---

## ğŸ› ï¸ Installation

### 1. Cloner le projet
```bash
git clone https://github.com/Makanjuol/AssistantVirtuel
cd AssistantVirtuel
````

### 2. CrÃ©er un environnement virtuel

```bash
python -m venv venv
source venv/bin/activate        # ou venv\Scripts\activate (Windows)
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

---

## ğŸ“¦ BibliothÃ¨ques Ã  installer

Le fichier `requirements.txt` inclut :

* `fastapi`
* `uvicorn`
* `python-dotenv`
* `openai`
* `requests`
* `speechrecognition`
* `pyttsx3`
* `pydub`

Et pour la version locale avec DeepSeek :

* [Installe Ollama](https://ollama.com/download)

Puis dans le terminal :

```bash
ollama run mistral
```

âš ï¸ Pour lâ€™audio `.mp3`, tu dois aussi :

* Installer **ffmpeg**

  * Avec winget install ffmpeg`
  * Ou : [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)

---
### ClÃ© OpenAI

CrÃ©e un fichier `.env` Ã  la racine :

```
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxx
```

Sans clÃ© valide, lâ€™assistant utilise **DeepSeek automatiquement**.

---

## Lancement

===============================
Assistant Vocal - Phase 1 (CLI)
===============================

Assistant vocal intelligent en ligne de commande :

- ğŸ™ï¸ Enregistre la voix avec un micro
- ğŸ“ Transcrit la voix en texte (speech_recognition)
- ğŸ¤– GÃ©nÃ¨re une rÃ©ponse avec GPT-3.5 ou DeepSeek (local)
- ğŸ”Š Lit la rÃ©ponse avec pyttsx3



Utilisation
-----------

1. Lancer DeepSeek si local :
   ollama run mistral

2. Lancer le programme :
   python -m AssistantCLI.main 




===============================
Assistant Vocal - Phase 2 (API REST + Interface Web)
===============================

Assistant vocal avec API FastAPI et interface web.

### 1. DÃ©marrer Ollama avec DeepSeek

```bash
ollama run mistral
```

### 2. Lancer le serveur FastAPI

```bash
uvicorn ApiRest.main:app --reload
```

### 3. Ouvrir lâ€™interface web

[http://localhost:8000](http://localhost:8000)

---

## Exemples dâ€™utilisation



1. Dans lâ€™interface :

   * Cliquer sur "Choisir un fichier" ou "Enregistrer la voix"
   * Cliquer sur "Envoyer"

2. Une fois envoyÃ©, s'afficheront:

   * La transcription de l'audio ou de l'enregistrement envoyÃ©
   * La rÃ©ponse gÃ©nÃ©rÃ©e par l'IA
   * La lecture vocale 
   * Lâ€™historique des Ã©changes ğŸ“œ

### ğŸ“ Exporter lâ€™historique

Clique sur **"Exporter lâ€™historique"** pour obtenir un fichier `pdf` de tous les Ã©changes.


---

##  Structure du projet

```
AssistantVirtuel/
â”œâ”€â”€ ApiRest/
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ endpoints/
â”‚       â”œâ”€â”€ assistant.py
â”‚       â”œâ”€â”€ upload.py
â”‚       â”œâ”€â”€ transcription.py
â”‚       â”œâ”€â”€ generation.py
â”‚       â””â”€â”€ synthesis.py
â”œâ”€â”€ AssistantCLI/
â”‚   â”œâ”€â”€ chat_engine.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ transcriber.py
â”‚   â”œâ”€â”€ recorder.py
â”‚   â””â”€â”€ VoiceOutout.py
â”œâ”€â”€ web_interface/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ uploaded_audio/
â”œâ”€â”€ response_audio/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ Readme.md


---


